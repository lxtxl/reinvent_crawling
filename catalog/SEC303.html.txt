내부 또는 민감한 데이터에서 LLM (Large Language Model)을 외부에 직면 할 때는 교육 데이터의 일부를 의도하지 않거나 부적절하게 공개하지 않아야합니다.민감한 데이터 공개로부터 보호하기 위해 일반적인 권장 사항은 이러한 복잡한 시스템을 비공개 고객 데이터로 훈련시키지 않는 것입니다.그러나 이것이 항상 가능하지는 않습니다.이 분필 대화는이 위험을 완화하는 방법을 다룹니다.소독, 익명화, 합성 데이터 생성, 집계 및 차이 프라이버시와 같은 데이터 최소화 원칙을 탐색하면서 이점과 트레이드 오프를 논의하십시오.