Gen AI 혁명이 전개됨에 따라 조직은 클라우드에서 GPU 워크로드를 확장하는 운영 문제를 탐색해야합니다.
Kubernetes는 AI 추론 또는 AI가 새로운 데이터로부터 결론을 분석하고 그려주는 방법과 관련하여 매력적이지만 도전적인 솔루션을 제공합니다.
AI 추론 워크로드를 최적화하려면 Kubernetes 및 AI 모델에 대한 깊은 이해가 필요합니다.
컨테이너, 특히 AI 워크로드에 대한 적절한 리소스 요청 및 한도를 설정하는 것은 까다 롭습니다.
잘못된 설정은 비용 초과 및/또는 비효율적 인 자원 활용으로 이어집니다.
이 세션에서는 GPU 인프라 최적화 문제를 극복하기 위해 AWS 및 NetApp을 사용하여 Kubernetes의 힘을 활용하는 방법을 알아보십시오.
이 프레젠테이션은 AWS 파트너 인 NetApp이 제공합니다.