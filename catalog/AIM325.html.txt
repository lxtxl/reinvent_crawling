대형 언어 모델 (LLM)은 정답을 생성 할 때 빠르게 향상되고 있지만 여전히 환각에 취약합니다.환각은 사실적으로 부정확하거나 신뢰할 수없는 정보를 가지고 있거나 교육 데이터와 일치하지 않는 응답입니다.이것은 조직이 생성 AI 응용 프로그램을 신뢰하고 배포 할 수 있는지 여부를 결정할 때 직면하는 가장 큰 장애물 중 하나입니다.이 워크숍에서 환각을 감지하고 줄이는 방법을 배우십시오.최신 기술과 기능을 활용하고 Amazon Bedrock의 응용 프로그램 아키텍처 패턴에 대해 배우고 진실성과 진실성을 향상시킵니다.참여하려면 노트북을 가져와야합니다.