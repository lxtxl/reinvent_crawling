이 건축업자 세션에서 Qlora 전략을 사용하여 단계별 구현 경험 미세 조정 LLAMA 3 8B를 얻으십시오.내장 디버깅 및 GPU 활용 메트릭에 액세스 할 수있는 메모리 효율적인 Pytorch Fully Sharded Data Parallel (Flested Data Parallel) 라이브러리를 사용하여 LLAMA 3 모델을 스케일로 미세 조정하는 방법에 대해 알아보십시오.Amazon Sagemaker가있는 맞춤형 딥 러닝 컨테이너를 사용하여 Amazon EC2 G5 인스턴스에서 이러한 대규모 교육 작업을 실행하십시오.Amazon Sagemaker의 GPU 리소스 인프라에서 Torchtune과 같은 자신의 라이브러리 선택을 어떻게 선택할 수 있는지 알아보십시오.참여하려면 노트북을 가져와야합니다.