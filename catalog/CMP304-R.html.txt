대형 언어 모델 (LLM)은 방대한 양의 데이터로 사전질을하고 추가 전문 교육없이 다양한 일반 목적 작업 및 벤치 마크에서 잘 수행됩니다.그러나 실제로는 작은 작업 별 또는 도메인 별 데이터 세트를 사용하여 모델을 미세 조정하여 사전 배치 된 LLM의 성능을 향상시키는 것이 일반적입니다.이 건축업자 세션에서 Amazon Sagemaker를 사용하여 AWS Trainium을 사용하여 사전에 포옹 페이스 LLM을 미세 조정 한 다음 미세 조정 된 모델을 추론하십시오.참여하려면 노트북을 가져와야합니다.