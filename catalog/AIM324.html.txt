이 워크숍에서는 Amazon Bedrock Guardrails를 사용하여 책임있는 생성 AI 응용 프로그램을 구축하는 데 깊이 설명하십시오.처음부터 생성 AI 응용 프로그램을 개발하고, 행동을 테스트하며, 언어 모델과 관련된 잠재적 위험과 과제에 대해 논의하십시오.가드 레일을 사용하여 바람직하지 않은 주제를 필터링하고, 유해한 컨텐츠를 차단하고, 신속한 주입 공격을 피하고, PII와 같은 민감한 정보를 처리합니다.마지막으로, 데이터에 근거하지 않은 모델 응답에서 환각을 감지하고 피하는 방법을 배우십시오.Amazon Bedrock에서 FMS 및 FITE FMS로 직접 맞춤형 맞춤형 가드 레일을 생성하고 적용하는 방법을 확인하여 생성 AI 응용 프로그램 내에서 책임있는 AI 정책을 구현하십시오.참여하려면 노트북을 가져와야합니다.