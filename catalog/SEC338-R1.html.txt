신속한 주사 공격은 생성 AI (Gen AI) 응용의 무결성과 안전성에 위험을 초래합니다.위협 행위자는 시스템을 조작하라는 프롬프트를 만들어 유해, 편견 또는 의도하지 않은 출력의 생성으로 이어질 수 있습니다.이 초크 토크에서는 즉각적인 주입 취약성을 방어하기위한 효과적인 전략을 탐색하십시오.강력한 입력 검증, 안전한 신속한 엔지니어링 원칙 및 포괄적 인 컨텐츠 중재 프레임 워크에 대해 알아보십시오.다양한 프롬프트와 관련 방어 메커니즘의 데모를 참조하십시오.이러한 모범 사례를 채택함으로써 생성 AI 응용 프로그램을 보호하고 조직에서 책임있는 AI 관행을 장려하는 데 도움이 될 수 있습니다.