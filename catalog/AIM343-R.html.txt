위험 평가는 책임있는 AI (RAI) 개발의 필수 부분이며 ISO 42001 및 EU AI Act와 같은 AI 표준 및 법률에서 점점 더 일반적인 요구 사항입니다.이 Chalk Talk는 생성 AI 애플리케이션에 대한 RAI 위험 평가를위한 모범 사례에 대한 소개, 제어 성, 진실성, 공정성, 견고성, 설명 가능성, 개인 정보 보호 및 보안, 투명성 및 거버넌스를 포함합니다.유해한 잠재적 사건의 심각성과 가능성을 추정하기 위해 예를 탐색하십시오.잠재적 인 위험 완화 전략으로서 모델 거버넌스, 편견, 설명 및 모니터링 및 서비스 카드 형태의 투명성에 대한 Amazon Sagemaker 툴링에 대해 알아보십시오.