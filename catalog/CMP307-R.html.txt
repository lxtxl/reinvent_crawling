대형 언어 모델 (LLM)은 광범위한 응용 프로그램에 현저한 영향을 미치지 만 규모에 따라 상당한 비용과 배포 문제가 발생합니다.이 워크숍에서는 AWS Fellentia2 기반 Amazon EC2 Inf2 인스턴스를 사용하여 효율적인 LLM 배포를위한 모범 사례를 탐색하여 성능과 비용을 최대화하십시오.연속 배치, 페이징주의, 플래시 관심 등과 같은 검토 기술을 배우고 포옹 얼굴 TGI 및 VLLM과 같은 서빙 라이브러리를 살펴보십시오.참여하려면 노트북을 가져와야합니다.